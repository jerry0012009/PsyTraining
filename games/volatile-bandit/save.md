# Volatile Bandit 任务数据保存说明

## 任务概述
Volatile Bandit任务是基于多臂老虎机（multi-armed bandit）范式的概率学习和决策制定实验，用于研究不确定环境下的学习适应和决策策略。被试需要在两个选项间进行选择以获得积分奖励，同时适应奖励概率的动态变化，测量学习能力和环境适应性。

## 数据保存机制

### 技术架构
- **实验框架**: jsPsych 实验心理学框架
- **核心插件**: poldrack-single-stim插件，支持动态刺激生成
- **辅助插件**: survey-text（问卷）
- **随机化**: jsPsych.randomization内置函数
- **进度跟踪**: HTML5 progress元素动态显示积分进度

### 任务设计

#### 刺激系统
- **视觉刺激**: 蓝色和绿色的几何图形
- **奖励显示**: 每个形状显示0-100之间的数值
- **互补原则**: 两个形状的奖励值总和始终等于100
- **反应方式**: 左右箭头键选择对应位置的形状
- **反馈系统**: 进度条显示累积积分，目标线标记奖励阈值

#### 实验阶段设计
1. **稳定阶段（Stage 1）**
   - 试验数量：120个试验
   - 奖励规律：一个刺激80%概率获得奖励
   - 获胜刺激：固定不变
   - 学习目标：发现并利用稳定的奖励规律

2. **波动阶段（Stage 2）**
   - 试验数量：170个试验
   - 奖励规律：高概率刺激每30-40个试验发生变化
   - 块结构：5个不同长度的块（30, 30, 30, 40, 40个试验）
   - 适应目标：检测环境变化并快速重新学习

### 保存的数据字段

#### 稳定阶段数据
```javascript
// 刺激反应试验
{
    trial_id: "stim_response",           // 刺激反应标识
    condition: "stable",                 // 稳定条件标识
    exp_stage: "test",                   // 实验阶段
    correct_response: 37|39,             // 正确反应键（左右箭头）
    correct_stim: "stim1|stim2",         // 正确刺激标识
    stim1_value: 0-100,                  // 刺激1的奖励值
    stim2_value: 0-100,                  // 刺激2的奖励值（100-stim1_value）
    key_press: 37|39,                    // 实际按键反应
    rt: 1234,                            // 反应时间（毫秒）
    timing_stim: 1500,                   // 刺激显示时间
    timing_response: 1500                // 反应时间窗口
}

// 反应确认试验
{
    trial_id: "show_response",           // 显示反应标识
    condition: "stable",                 // 条件类型
    // 包含相同的刺激和反应信息
}

// 反馈试验
{
    trial_id: "FB",                      // 反馈标识
    condition: "stable",                 // 条件类型
    // 包含相同的刺激和反应信息
    // 反馈显示正确选择和奖励获得情况
}
```

#### 波动阶段数据
```javascript
{
    trial_id: "stim_response|show_response|FB", // 试验类型
    condition: "volatile",               // 波动条件标识
    block: "block_1|block_2",           // 块编号（指示转换点）
    exp_stage: "test",                   // 实验阶段
    correct_response: 37|39,             // 正确反应键
    correct_stim: "stim1|stim2",         // 当前块的高概率刺激
    stim1_value: 0-100,                  // 动态奖励值
    stim2_value: 0-100,                  // 互补奖励值
    key_press: 37|39,                    // 被试反应
    rt: 1234                             // 反应时间
}
```

### 奖励概率机制

#### 稳定阶段概率设计
```javascript
// 80%-20%的固定概率分布
var static_winners = jsPsych.randomization.repeat([0, 0, 0, 1], stage1_trials / 4);
// 0代表stim1获胜，1代表stim2获胜
// 数组中3个0和1个1确保80%-20%的概率分布
```

#### 波动阶段概率设计
```javascript
// 概率转换机制
var volatile_blocks = [30, 30, 30, 40, 40];  // 各块试验数
var volatile_proportions = [0, 0, 1, 1, 1] or [0, 0, 0, 1, 1]; // 获胜刺激模式

// 块间转换规律
// 块1-3：某一刺激高概率（80%）获胜
// 块4-5：另一刺激高概率（80%）获胜
// 转换时机：块间边界，无预警信号
```

### 动态奖励系统

#### 奖励值生成
```javascript
// 每个试验随机生成互补的奖励值
var stim1_value = Math.floor(Math.random() * 101);  // 0-100随机值
var stim2_value = 100 - stim1_value;                // 互补值

// 奖励获得条件
if (response == correct_response) {
    progress_value += selected_stim_value * 0.022;   // 积分增加
}
```

#### 进度反馈系统
```javascript
var getFBBar = function() {
    return '<progress class = feedback_bar value = "' + progress_value + 
           '" max = "100"></progress><div class = goal_1></div><div class = goal_2></div>';
}
// progress_value: 当前积分进度（0-100）
// goal_1, goal_2: 奖励阈值标记线
```

### 试验流程设计

#### 三阶段试验结构
1. **刺激呈现**: 显示两个形状和奖励值，等待选择
2. **反应确认**: 高亮显示被试选择的形状
3. **结果反馈**: 显示正确选择和进度条更新

#### 时间参数控制
- **刺激显示**: 1500ms固定显示时间
- **反应窗口**: 1500ms最大反应时间
- **反馈显示**: 1500ms反馈展示时间
- **试验间间隔**: 0ms，连续试验呈现

### 学习与适应评估

#### 稳定阶段学习指标
1. **学习速度**: 达到稳定表现所需试验数
2. **学习曲线**: 正确选择率随试验的变化
3. **稳定表现**: 后期试验的选择准确性
4. **价值敏感性**: 对不同奖励值的反应模式

#### 波动阶段适应指标
1. **变化检测**: 发现环境变化的速度
2. **重学习能力**: 适应新概率分布的效率
3. **认知灵活性**: 切换策略的能力
4. **持续学习**: 在不确定性中的表现维持

### 决策策略分析

#### 学习算法建模
1. **强化学习模型**: Q-learning和temporal difference learning
2. **贝叶斯学习**: 概率信念的更新和维持
3. **选择策略**: ε-greedy, softmax, Thompson sampling
4. **元学习**: 学习率的动态调整

#### 个体差异指标
- **探索-利用平衡**: 已知好选项vs新选项探索
- **学习率**: 新信息整合的速度
- **遗忘率**: 旧信息衰减的速度
- **不确定性容忍**: 在模糊情境中的决策偏好

### 认知机制评估

#### 执行功能与学习
1. **工作记忆**: 维持奖励历史和概率估计
2. **注意控制**: 专注相关信息，忽略干扰
3. **认知灵活性**: 根据反馈调整策略
4. **抑制控制**: 抑制自动化的不当反应

#### 情绪与动机因素
- **奖励敏感性**: 对积分奖励的敏感程度
- **损失规避**: 对负面结果的回避倾向
- **风险偏好**: 在不确定性下的选择倾向
- **持续动机**: 维持任务参与的内在动机

### 数据分析方法

#### 基础行为指标
1. **选择准确率**: 选择高概率选项的比例
2. **反应时间**: 决策制定的速度
3. **学习曲线**: 表现随时间的变化轨迹
4. **转换检测**: 发现环境变化的试验点

#### 计算建模分析
1. **模型拟合**: 使用最大似然估计拟合学习模型
2. **参数估计**: 学习率、探索参数、温度参数
3. **模型比较**: AIC/BIC信息准则比较不同模型
4. **参数恢复**: 验证模型参数的可信度

### 临床应用指标

#### 认知功能评估
- **学习障碍**: 概率学习能力缺陷的识别
- **适应能力**: 环境变化适应的灵活性评估
- **决策能力**: 不确定性下的决策质量
- **冲动控制**: 即时奖励vs长期利益的权衡

#### 神经精神疾病
1. **抑郁症**: 奖励学习缺陷和动机不足
2. **焦虑症**: 不确定性回避和风险敏感性增加
3. **ADHD**: 注意缺陷对学习过程的影响
4. **强迫症**: 过度的确定性寻求行为

### 数据质量控制

#### 参与度监控
- **反应时间分布**: 检测过快或过慢反应
- **选择模式**: 识别随机或固化的反应模式
- **学习证据**: 验证真实学习vs随机表现
- **注意检查**: 阶段间插入注意力监控

#### 数据筛选标准
- **最低学习率**: 稳定阶段达到基本学习水平
- **反应变异性**: 反应时间的合理变异范围
- **策略一致性**: 决策策略的内在一致性
- **任务参与**: 持续的任务投入和努力

### 数据导出格式
jsPsych自动保存为JSON格式，包含：
- 每个试验的选择、反应时间和反馈信息
- 稳定和波动阶段的完整试验序列
- 块结构和概率转换的详细记录
- 可用于计算建模和策略分析的原始数据

## 临床应用价值
Volatile Bandit任务广泛应用于：
- **学习能力评估**: 概率学习和适应性学习能力测试
- **决策功能评估**: 不确定性下的决策制定能力
- **认知灵活性评估**: 环境变化的适应和策略转换能力
- **神经精神疾病研究**: 抑郁、焦虑、ADHD等的决策功能评估
- **发展心理学**: 儿童和青少年学习发展轨迹研究

## 注意事项
- 确保被试理解奖励值互补原则（总和为100）
- 强调积分最大化目标而非单纯的正确率
- 注意波动阶段环境变化对策略调整的影响
- 监控被试是否采用有效的学习策略而非随机选择